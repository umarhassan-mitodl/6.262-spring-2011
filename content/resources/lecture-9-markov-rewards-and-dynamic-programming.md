---
content_type: resource
description: ''
end_time: ''
file: null
file_size: '190093891'
hide_download: true
hide_download_original: null
learning_resource_types:
- Lecture Videos
license: https://creativecommons.org/licenses/by-nc-sa/4.0/
ocw_type: ''
optional_tab_title: Lecture Slides
optional_text: Markov Rewards and Dynamic Programming ([PDF](/courses/6-262-discrete-stochastic-processes-spring-2011/resources/mit6_262s11_lec09))
parent_title: Video Lectures
parent_type: CourseSection
related_resources_text: ''
resource_index_text: ''
resourcetype: Video
start_time: ''
title: 'Lecture 9: Markov Rewards and Dynamic Programming'
uid: a112768d-68ae-aa02-d050-46923645c91a
video_files:
  archive_url: http://www.archive.org/download/MIT6.262S11/MIT6_262S11_lec09_300k.mp4
  video_captions_file: /courses/6-262-discrete-stochastic-processes-spring-2011/a80eda96e606583cb4618748d29c6088_mNGVkKeMUtc.vtt
  video_thumbnail_file: https://img.youtube.com/vi/mNGVkKeMUtc/default.jpg
  video_transcript_file: /courses/6-262-discrete-stochastic-processes-spring-2011/2dc04a342219f0dc8415028718f7126f_mNGVkKeMUtc.pdf
video_metadata:
  youtube_id: mNGVkKeMUtc
---

**Description:** This lecture covers rewards for Markov chains, expected first passage time, and aggregate rewards with a final reward. The professor then moves on to discuss dynamic programming and the dynamic programming algorithm.

**Instructor:** Prof. Robert Gallager

